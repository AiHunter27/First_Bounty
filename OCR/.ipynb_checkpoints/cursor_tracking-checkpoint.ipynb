{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbea0d6",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breif explanation about note book\n",
    "\n",
    "# using open cv templet matching to match cursor image in video to track that cursor in the video and \n",
    "# i have implemented this in three variation\n",
    "# variation one :-test all 6 method and find which whcih suits your use case\n",
    "# variation two :-As video will be of diffent resolution and templet matching might fail so resized curssor into multiple resolution so it works for all videos and images\n",
    "# variation three :-Multiple cursor detection in same video\n",
    "\n",
    "\n",
    "#note:- i have used only 2 frames per second u can change that value as per your requirement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d83a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21933f6c",
   "metadata": {},
   "source": [
    "# Pytesseract initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\Pathora\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe'###########path to pytesseract file#########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b055e8d4",
   "metadata": {},
   "source": [
    "# Variation one\n",
    "# Testing All methods and see what suits best fro your use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('D:/documents/data/testvideo.mp4')\n",
    "template = cv2.imread('D:/documents/data/pointer_40.png', cv2.IMREAD_GRAYSCALE)\n",
    "template = cv2.convertScaleAbs(template)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    for meth in methods:\n",
    "        method = eval(meth)\n",
    "        print(\"meth:-{}\\nmethod:-{}\".format(meth,method))\n",
    "        # Apply template Matching\n",
    "        res = cv2.matchTemplate(gray_frame,template,method)\n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "        if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        if eval(meth) ==0:\n",
    "            pass\n",
    "#             cv2.rectangle(frame,top_left, bottom_right, (0,0,255), 2)\n",
    "        elif eval(meth)==1:\n",
    "            cv2.rectangle(frame,top_left, bottom_right, (255,0,0), 2)\n",
    "#         elif eval(meth)==2:\n",
    "# #             cv2.rectangle(frame,top_left, bottom_right, (0,255,0), 2)\n",
    "#         elif eval(meth)==3:\n",
    "# #             cv2.rectangle(frame,top_left, bottom_right, (0,0,0), 2)\n",
    "#         elif eval(meth)==4:\n",
    "# #             cv2.rectangle(frame,top_left, bottom_right, (0,255,255), 2)\n",
    "#         elif eval(meth)==5:\n",
    "#             cv2.rectangle(frame,top_left, bottom_right, (0,0,220), 2)\n",
    "            \n",
    "            \n",
    "        cv2.imshow('Matched', frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and destroy the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a12e3",
   "metadata": {},
   "source": [
    "# find your video fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a868b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"path to your video\"\n",
    "cap = cv.VideoCapture(path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"Video frame rate:\", fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c24a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variation two\n",
    "#resizing templete to multiple resolutions and also draw ROI box around cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545539b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('D:/documents/data/testvideo.mp4')\n",
    "template = cv2.imread('D:/documents/data/pointer_40.png', cv2.IMREAD_GRAYSCALE)\n",
    "template = cv2.convertScaleAbs(template)\n",
    "# w, h = template.shape[::-1]\n",
    "roi_list = []\n",
    "threshold=0.7\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Loop over different scales\n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) % 15 == 0:# change value to increase or decrease your fps\n",
    "        for scale in np.linspace(0.2, 1.0,8)[::-1]:# resizing into 8 other sizes to find templet size(change as per your requirement)\n",
    "            # Resize the template\n",
    "#             print(scale)\n",
    "            resized = cv2.resize(template, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "            w, h = resized.shape[::-1]\n",
    "#             print(w,h)\n",
    "            # Perform template matching\n",
    "            res = cv2.matchTemplate(gray_frame, resized, cv.TM_CCOEFF_NORMED)\n",
    "            loc = np.where(res >= threshold)\n",
    "            for pt in zip(*loc[::-1]):\n",
    "#                 roi = gray_frame[pt[1]:pt[1]+250, pt[0]:pt[0]+250]\n",
    "                roi = gray_frame[pt[0]-25:pt[0]+25,pt[1]-250:pt[1]+250]\n",
    "                roi_list.append(roi)\n",
    "        #         print(text)\n",
    "                cv2.rectangle(frame, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
    "                cv2.rectangle(frame,(pt[0]-250,pt[1]-25),(pt[0]+250, pt[1]+25),(255,0,0),2)\n",
    "        cv.imshow(\"res\",frame)\n",
    "        key = cv.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the video capture and destroy the windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce628c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruuning ocr on my ROI(Region of interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee6a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in roi_list:\n",
    "#     print(np.count_nonzero(255),len(i))\n",
    "    text = pytesseract.image_to_string(i)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e8af5",
   "metadata": {},
   "source": [
    "# variation three \n",
    "# Template Matching with Multiple Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62cc74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture('D:/documents/data/testvideo.mp4')\n",
    "# img_rgb = cv.imread('mario.png')\n",
    "\n",
    "# img_gray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)\n",
    "template = cv.imread('D:/documents/data/pointer_40.png', cv.IMREAD_GRAYSCALE)\n",
    "template = cv.convertScaleAbs(template)\n",
    "w, h = template.shape[::-1]\n",
    "roi_list = []\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    res = cv.matchTemplate(gray_frame,template,cv.TM_CCOEFF_NORMED)#cv.TM_CCOEFF_NORMED\n",
    "    threshold = 0.48\n",
    "    loc = np.where( res >= threshold)\n",
    "#     print(loc)\n",
    "   \n",
    "    for pt in zip(*loc[::-1]):\n",
    "        roi = gray_frame[pt[1]:pt[1]+250, pt[0]:pt[0]+250]\n",
    "        roi_list.append(roi)\n",
    "#         text = pytesseract.image_to_string(roi)\n",
    "#         if text not in textlist:\n",
    "#             textlist.append(text)\n",
    "            \n",
    "#         print(text)\n",
    "        cv.rectangle(frame, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
    "    cv.imshow(\"res\",frame)\n",
    "    key = cv.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and destroy the windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a06216",
   "metadata": {},
   "outputs": [],
   "source": [
    "textlist = []\n",
    "for i in roi_list:\n",
    "    text = pytesseract.image_to_string(i)\n",
    "    print(text)\n",
    "    print(\"===================\")\n",
    "    if text not in textlist:\n",
    "        textlist.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da9677f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18f337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b545aa0e",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6dd214",
   "metadata": {},
   "outputs": [],
   "source": [
    "textlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392dd628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "for i in methods:\n",
    "    print(i,eval(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"template\",template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba89805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture('D:/documents/data/testvideo.mp4')\n",
    "template = cv.imread('D:/documents/data/cursor_image_resize.png', cv.IMREAD_GRAYSCALE)\n",
    "template = cv.convertScaleAbs(template)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    for meth in methods:\n",
    "        method = eval(meth)\n",
    "        # Apply template Matching\n",
    "        res = cv.matchTemplate(gray_frame, template, method)\n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "        if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        cv.rectangle(frame, top_left, bottom_right, 255, 2)\n",
    "        cv.imshow('Matched', frame)\n",
    "        key = cv2.waitKey(0)\n",
    "    if key == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68b9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66198582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e20f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8f470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture('D:/documents/data/testvideo.mp4')\n",
    "\n",
    "# Convert the video to grayscale\n",
    "rate, first_frame = cap.read()\n",
    "gray_first_frame = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Select the area of interest (AOI)\n",
    "x, y, w, h = cv2.selectROI('Select AOI', first_frame)\n",
    "gray_roi = gray_first_frame[y:y+h, x:x+w]\n",
    "\n",
    "# Define a template for the mouse cursor\n",
    "template = cv2.imread('D:/documents/data/cursor_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Loop through each frame of the video\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Search for the mouse cursor in the AOI using template matching\n",
    "    res = cv2.matchTemplate(gray_frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "    threshold = 0.5\n",
    "    loc = np.where(res >= threshold)\n",
    "    print(loc)\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        cv2.circle(frame, (pt[0]+int(template.shape[1]/2), pt[1]+int(template.shape[0]/2)), 10, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and destroy the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834ee5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
