{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d83a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "433b342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\Pathora\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f464d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"D:/documents/data/testvideo.mp4\")\n",
    "template = cv2.imread('D:/documents/data/cursor_image_resize_40.png', cv.IMREAD_GRAYSCALE)\n",
    "template = cv2.convertScaleAbs(template)\n",
    "w, h = template.shape[:2]\n",
    "\n",
    "\n",
    "# read video frame by farme\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "#     gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8b182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = cv2.imread('D:/documents/data/cursor150.png', cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79ccf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(40):\n",
    "    print(template[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad0309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a308b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe20e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture('D:/documents/data/testvideo.mp4')\n",
    "template = cv.imread('D:/documents/data/pointer_40.png', cv.IMREAD_GRAYSCALE)\n",
    "template = cv.convertScaleAbs(template)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "\n",
    "#test1\n",
    "\n",
    "# Define the template image\n",
    "# template_path = 'D:/documents/data/cursor.svg'\n",
    "# template = cv.imread(template_path, cv.IMREAD_GRAYSCALE)\n",
    "# if template is None:\n",
    "#     raise Exception(f\"Error: Unable to load template image at {template_path}\")\n",
    "# template = cv.convertScaleAbs(template)\n",
    "# w, h = template.shape[::-1]\n",
    "\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    for meth in methods:\n",
    "        method = eval(meth)\n",
    "        print(\"meth:-{}\\nmethod:-{}\".format(meth,method))\n",
    "        # Apply template Matching\n",
    "        res = cv.matchTemplate(gray_frame,template,method)\n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "        if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        if eval(meth) ==0:\n",
    "            pass\n",
    "#             cv.rectangle(frame,top_left, bottom_right, (0,0,255), 2)\n",
    "        elif eval(meth)==1:\n",
    "            cv.rectangle(frame,top_left, bottom_right, (255,0,0), 2)\n",
    "#         elif eval(meth)==2:\n",
    "# #             cv.rectangle(frame,top_left, bottom_right, (0,255,0), 2)\n",
    "#         elif eval(meth)==3:\n",
    "# #             cv.rectangle(frame,top_left, bottom_right, (0,0,0), 2)\n",
    "#         elif eval(meth)==4:\n",
    "# #             cv.rectangle(frame,top_left, bottom_right, (0,255,255), 2)\n",
    "#         elif eval(meth)==5:\n",
    "#             cv.rectangle(frame,top_left, bottom_right, (0,0,220), 2)\n",
    "            \n",
    "            \n",
    "        cv.imshow('Matched', frame)\n",
    "    key = cv.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and destroy the windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a12e3",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8085c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_num = 0\n",
    "path= \"D:/documents/data/testvideo.mp4\"\n",
    "path[18:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b23c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "path[18:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907045bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a868b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"D:/documents/data/testvideo.mp4\"\n",
    "cap = cv.VideoCapture(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c24a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(\"Video frame rate:\", fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd3bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_num = 0\n",
    "frame_interval = int(fps / 2)\n",
    "try:\n",
    "    os.mkdir(path[:17]+\"/\"+path[18:27])\n",
    "except Exception as e:\n",
    "    print(e,\"file already exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcddbd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "while True:\n",
    "    # Read the current frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        # If the video has ended, break the loop\n",
    "        break\n",
    "    \n",
    "    # Save the current frame as an image\n",
    "    if cap.get(cv.CAP_PROP_POS_FRAMES) % frame_interval == 0:\n",
    "        cv.imshow(\"test\",frame)\n",
    "#         cv.imwrite(path[:17]+\"/\"+path[18:27]+\"/\"+\"frame_{}.jpg\".format(frame_num), frame)\n",
    "    frame_num += 1\n",
    "\n",
    "    # Exit the loop if the 'q' key is pressed\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c42486",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(1000/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(i%30,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545539b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture('D:/documents/data/testvideo.mp4')\n",
    "template = cv.imread('D:/documents/data/pointer_40.png', cv.IMREAD_GRAYSCALE)\n",
    "template = cv.convertScaleAbs(template)\n",
    "# w, h = template.shape[::-1]\n",
    "roi_list = []\n",
    "threshold=0.7\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Loop over different scales\n",
    "    if cap.get(cv.CAP_PROP_POS_FRAMES) % 15 == 0:\n",
    "        for scale in np.linspace(0.2, 1.0,8)[::-1]:\n",
    "            # Resize the template\n",
    "#             print(scale)\n",
    "            resized = cv.resize(template, None, fx=scale, fy=scale, interpolation=cv.INTER_CUBIC)\n",
    "            w, h = resized.shape[::-1]\n",
    "#             print(w,h)\n",
    "            # Perform template matching\n",
    "            res = cv.matchTemplate(gray_frame, resized, cv.TM_CCOEFF_NORMED)\n",
    "            loc = np.where(res >= threshold)\n",
    "            for pt in zip(*loc[::-1]):\n",
    "#                 roi = gray_frame[pt[1]:pt[1]+250, pt[0]:pt[0]+250]\n",
    "                roi = gray_frame[pt[0]-25:pt[0]+25,pt[1]-250:pt[1]+250]\n",
    "                roi_list.append(roi)\n",
    "        #         print(text)\n",
    "                cv.rectangle(frame, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
    "                cv.rectangle(frame,(pt[0]-250,pt[1]-25),(pt[0]+250, pt[1]+25),(255,0,0),2)\n",
    "        cv.imshow(\"res\",frame)\n",
    "        key = cv.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the video capture and destroy the windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee6a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Createyimrount\n",
      "\n",
      "CreateQmrount\n",
      "\n",
      "CreateQmrount\n",
      "\n",
      "Qigrount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Qigrount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Qigrount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Qigrount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Qigrount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Qigrount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Qigrount\n",
      "\n",
      "Cirount\n",
      "\n",
      "Cirount\n",
      "\n",
      "CreateQijrount\n",
      "\n",
      "\n",
      "\n",
      ", Need help?\n",
      "\n",
      ", Need help?\n",
      "\n",
      "fiery Fy\n",
      "\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "tile cannot extend outside image",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mD:\\documents\\env_d\\tf\\lib\\site-packages\\PIL\\ImageFile.py:515\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m()\n\u001b[0;32m    516\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m roi_list:\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#     print(np.count_nonzero(255),len(i))\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(text)\n",
      "File \u001b[1;32mD:\\documents\\env_d\\tf\\lib\\site-packages\\pytesseract\\pytesseract.py:423\u001b[0m, in \u001b[0;36mimage_to_string\u001b[1;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    421\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m--> 423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\documents\\env_d\\tf\\lib\\site-packages\\pytesseract\\pytesseract.py:426\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    421\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    424\u001b[0m     Output\u001b[38;5;241m.\u001b[39mBYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[0;32m    425\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: run_and_get_output(\u001b[38;5;241m*\u001b[39margs)},\n\u001b[1;32m--> 426\u001b[0m     Output\u001b[38;5;241m.\u001b[39mSTRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    427\u001b[0m }[output_type]()\n",
      "File \u001b[1;32mD:\\documents\\env_d\\tf\\lib\\site-packages\\pytesseract\\pytesseract.py:277\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[1;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_and_get_output\u001b[39m(\n\u001b[0;32m    268\u001b[0m     image,\n\u001b[0;32m    269\u001b[0m     extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m     return_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m ):\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[0;32m    278\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    279\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: input_filename,\n\u001b[0;32m    280\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[0;32m    286\u001b[0m         }\n\u001b[0;32m    288\u001b[0m         run_tesseract(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[1;32mD:\\documents\\env_d\\tf\\lib\\site-packages\\pytesseract\\pytesseract.py:199\u001b[0m, in \u001b[0;36msave\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m    197\u001b[0m         image, extension \u001b[38;5;241m=\u001b[39m prepare(image)\n\u001b[0;32m    198\u001b[0m         input_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_input\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 199\u001b[0m         \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\u001b[38;5;241m.\u001b[39mname, input_file_name\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\documents\\env_d\\tf\\lib\\site-packages\\PIL\\Image.py:2432\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2429\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2431\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2432\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2433\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   2434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32mD:\\documents\\env_d\\tf\\lib\\site-packages\\PIL\\PngImagePlugin.py:1407\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     _write_multiple_frames(im, fp, chunk, rawmode, default_image, append_images)\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1407\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[1;32mD:\\documents\\env_d\\tf\\lib\\site-packages\\PIL\\ImageFile.py:519\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    517\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 519\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    521\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mD:\\documents\\env_d\\tf\\lib\\site-packages\\PIL\\ImageFile.py:530\u001b[0m, in \u001b[0;36m_encode_tile\u001b[1;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[0;32m    528\u001b[0m encoder \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39m_getencoder(im\u001b[38;5;241m.\u001b[39mmode, e, a, im\u001b[38;5;241m.\u001b[39mencoderconfig)\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 530\u001b[0m     \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetimage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoder\u001b[38;5;241m.\u001b[39mpushes_fd:\n\u001b[0;32m    532\u001b[0m         encoder\u001b[38;5;241m.\u001b[39msetfd(fp)\n",
      "\u001b[1;31mSystemError\u001b[0m: tile cannot extend outside image"
     ]
    }
   ],
   "source": [
    "for i in roi_list:\n",
    "#     print(np.count_nonzero(255),len(i))\n",
    "    text = pytesseract.image_to_string(i)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e8af5",
   "metadata": {},
   "source": [
    "# best templet matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62cc74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture('D:/documents/data/testvideo.mp4')\n",
    "# img_rgb = cv.imread('mario.png')\n",
    "\n",
    "# img_gray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)\n",
    "template = cv.imread('D:/documents/data/pointer_40.png', cv.IMREAD_GRAYSCALE)\n",
    "template = cv.convertScaleAbs(template)\n",
    "w, h = template.shape[::-1]\n",
    "roi_list = []\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    res = cv.matchTemplate(gray_frame,template,cv.TM_CCOEFF_NORMED)#cv.TM_CCOEFF_NORMED\n",
    "    threshold = 0.48\n",
    "    loc = np.where( res >= threshold)\n",
    "#     print(loc)\n",
    "   \n",
    "    for pt in zip(*loc[::-1]):\n",
    "        roi = gray_frame[pt[1]:pt[1]+250, pt[0]:pt[0]+250]\n",
    "        roi_list.append(roi)\n",
    "#         text = pytesseract.image_to_string(roi)\n",
    "#         if text not in textlist:\n",
    "#             textlist.append(text)\n",
    "            \n",
    "#         print(text)\n",
    "        cv.rectangle(frame, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
    "    cv.imshow(\"res\",frame)\n",
    "    key = cv.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and destroy the windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a06216",
   "metadata": {},
   "outputs": [],
   "source": [
    "textlist = []\n",
    "for i in roi_list:\n",
    "    text = pytesseract.image_to_string(i)\n",
    "    print(text)\n",
    "    print(\"===================\")\n",
    "    if text not in textlist:\n",
    "        textlist.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6dd214",
   "metadata": {},
   "outputs": [],
   "source": [
    "textlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392dd628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "for i in methods:\n",
    "    print(i,eval(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"template\",template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba89805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture('D:/documents/data/testvideo.mp4')\n",
    "template = cv.imread('D:/documents/data/cursor_image_resize.png', cv.IMREAD_GRAYSCALE)\n",
    "template = cv.convertScaleAbs(template)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    for meth in methods:\n",
    "        method = eval(meth)\n",
    "        # Apply template Matching\n",
    "        res = cv.matchTemplate(gray_frame, template, method)\n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "        if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        cv.rectangle(frame, top_left, bottom_right, 255, 2)\n",
    "        cv.imshow('Matched', frame)\n",
    "        key = cv2.waitKey(0)\n",
    "    if key == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68b9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66198582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e20f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8f470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture('D:/documents/data/testvideo.mp4')\n",
    "\n",
    "# Convert the video to grayscale\n",
    "rate, first_frame = cap.read()\n",
    "gray_first_frame = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Select the area of interest (AOI)\n",
    "x, y, w, h = cv2.selectROI('Select AOI', first_frame)\n",
    "gray_roi = gray_first_frame[y:y+h, x:x+w]\n",
    "\n",
    "# Define a template for the mouse cursor\n",
    "template = cv2.imread('D:/documents/data/cursor_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Loop through each frame of the video\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Search for the mouse cursor in the AOI using template matching\n",
    "    res = cv2.matchTemplate(gray_frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "    threshold = 0.5\n",
    "    loc = np.where(res >= threshold)\n",
    "    print(loc)\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        cv2.circle(frame, (pt[0]+int(template.shape[1]/2), pt[1]+int(template.shape[0]/2)), 10, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and destroy the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834ee5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
